<!DOCTYPE html><html lang="zh-CN"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v4.16.19"><meta name="description" content="Blog post"><title>Untitled</title><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Lora:ital,wght@0,400;0,600;1,400&display=swap" rel="stylesheet"><link rel="stylesheet" href="/_astro/_title_.U5p-WJ3X.css"><script type="module">const e=()=>{document.querySelectorAll(".animate").forEach((t,s)=>{setTimeout(()=>{t.classList.add("show")},s*150)})};e();document.addEventListener("astro:after-swap",e);
</script></head> <body> <header> <div class="mx-auto max-w-screen-sm px-5">  <div class="flex flex-wrap gap-y-2 justify-between"> <a href="/" class="font-semibold hover:underline underline-offset-2">
Blog
</a> <nav class="flex gap-1">  <a href="/archive" class="hover:underline underline-offset-2"> Archive </a> <span>/</span> <a href="/tags" class="hover:underline underline-offset-2"> Tags </a> <span>/</span> <a href="/categories" class="hover:underline underline-offset-2"> Categories </a> <span>/</span> <a href="/about" class="hover:underline underline-offset-2"> About </a>  </nav> </div>  </div> </header> <main>  <div class="mx-auto max-w-screen-sm px-5">  <div class="animate"> <a href="/archive" class="hover:underline underline-offset-2">
← Back to archive
</a> </div> <div class="space-y-1 my-10"> <div class="animate flex items-center gap-1.5"> <div class="font-base text-sm"> <time datetime="2018-04-08T00:00:00.000Z"> April 8, 2018 </time> </div> </div> <div class="animate text-2xl font-semibold text-black dark:text-white">  </div>  </div> <article class="animate"> <h2 id="title-seq2seq-model解析date-2018-04-08-173150categories-mltags-ml">title: seq2seq model解析
date: 2018-04-08 17:31:50
categories: ML
tags: [ML]</h2>
<p><a href="http://cyruschiu.github.io/2017/02/24/learning-Tensoflow-Seq2Seq-for-translate/">原文链接</a></p>
<h3 id="train">train</h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">with</span><span style="color:#E1E4E8"> tf.Session() </span><span style="color:#F97583">as</span><span style="color:#E1E4E8"> sess:</span></span>
<span class="line"><span style="color:#6A737D">   # 區塊1，模型初始化</span></span>
<span class="line"><span style="color:#6A737D">   # Create model.</span></span>
<span class="line"><span style="color:#79B8FF">   print</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">"Creating </span><span style="color:#79B8FF">%d</span><span style="color:#9ECBFF"> layers of </span><span style="color:#79B8FF">%d</span><span style="color:#9ECBFF"> units."</span><span style="color:#F97583"> %</span><span style="color:#E1E4E8"> (</span><span style="color:#79B8FF">FLAGS</span><span style="color:#E1E4E8">.num_layers, </span><span style="color:#79B8FF">FLAGS</span><span style="color:#E1E4E8">.size))</span></span>
<span class="line"><span style="color:#6A737D">   # 透過 create_model() 方法創建一個 seq2seq_model</span></span>
<span class="line"><span style="color:#E1E4E8">   model </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> create_model(sess, </span><span style="color:#79B8FF">False</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#E1E4E8">   </span></span>
<span class="line"><span style="color:#6A737D">   # 區塊2，讀入資料</span></span>
<span class="line"><span style="color:#6A737D">   # Read data into buckets and compute their sizes.</span></span>
<span class="line"><span style="color:#79B8FF">   print</span><span style="color:#E1E4E8"> (</span><span style="color:#9ECBFF">"Reading development and training data (limit: </span><span style="color:#79B8FF">%d</span><span style="color:#9ECBFF">)."</span></span>
<span class="line"><span style="color:#F97583">          %</span><span style="color:#79B8FF"> FLAGS</span><span style="color:#E1E4E8">.max_train_data_size)</span></span>
<span class="line"><span style="color:#6A737D">   # read_data 函數讀取 train, dev 的路徑，</span></span>
<span class="line"><span style="color:#E1E4E8">   dev_set </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> read_data(from_dev, to_dev)</span></span>
<span class="line"><span style="color:#E1E4E8">   train_set </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> read_data(from_train, to_train, </span><span style="color:#79B8FF">FLAGS</span><span style="color:#E1E4E8">.max_train_data_size)</span></span>
<span class="line"><span style="color:#E1E4E8">   train_bucket_sizes </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> [</span><span style="color:#79B8FF">len</span><span style="color:#E1E4E8">(train_set[b]) </span><span style="color:#F97583">for</span><span style="color:#E1E4E8"> b </span><span style="color:#F97583">in</span><span style="color:#FFAB70"> xrange</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">len</span><span style="color:#E1E4E8">(_buckets))]</span></span>
<span class="line"><span style="color:#E1E4E8">   train_total_size </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> float</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">sum</span><span style="color:#E1E4E8">(train_bucket_sizes))</span></span>
<span class="line"><span style="color:#E1E4E8">   train_buckets_scale </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> [</span><span style="color:#79B8FF">sum</span><span style="color:#E1E4E8">(train_bucket_sizes[:i </span><span style="color:#F97583">+</span><span style="color:#79B8FF"> 1</span><span style="color:#E1E4E8">]) </span><span style="color:#F97583">/</span><span style="color:#E1E4E8"> train_total_size</span></span>
<span class="line"><span style="color:#F97583">                          for</span><span style="color:#E1E4E8"> i </span><span style="color:#F97583">in</span><span style="color:#FFAB70"> xrange</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">len</span><span style="color:#E1E4E8">(train_bucket_sizes))]</span></span>
<span class="line"><span style="color:#F97583">   while</span><span style="color:#79B8FF"> True</span><span style="color:#E1E4E8">:</span></span>
<span class="line"><span style="color:#6A737D">     # 區塊3，建立 batch</span></span>
<span class="line"><span style="color:#6A737D">     # Choose a bucket according to data distribution. We pick a random number</span></span>
<span class="line"><span style="color:#6A737D">     # in [0, 1] and use the corresponding interval in train_buckets_scale.</span></span>
<span class="line"><span style="color:#E1E4E8">     random_number_01 </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> np.random.random_sample()</span></span>
<span class="line"><span style="color:#E1E4E8">     bucket_id </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> min</span><span style="color:#E1E4E8">([i </span><span style="color:#F97583">for</span><span style="color:#E1E4E8"> i </span><span style="color:#F97583">in</span><span style="color:#FFAB70"> xrange</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">len</span><span style="color:#E1E4E8">(train_buckets_scale))</span></span>
<span class="line"><span style="color:#F97583">                      if</span><span style="color:#E1E4E8"> train_buckets_scale[i] </span><span style="color:#F97583">></span><span style="color:#E1E4E8"> random_number_01])</span></span>
<span class="line"><span style="color:#6A737D">     # Get a batch and make a step.</span></span>
<span class="line"><span style="color:#E1E4E8">     start_time </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> time.time()</span></span>
<span class="line"><span style="color:#E1E4E8">     encoder_inputs, decoder_inputs, target_weights </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> model.get_batch(</span></span>
<span class="line"><span style="color:#E1E4E8">         train_set, bucket_id)</span></span>
<span class="line"><span style="color:#6A737D">     # 區塊4，訓練</span></span>
<span class="line"><span style="color:#E1E4E8">     _, step_loss, _ </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> model.step(sess, encoder_inputs, decoder_inputs,</span></span>
<span class="line"><span style="color:#E1E4E8">                                  target_weights, bucket_id, </span><span style="color:#79B8FF">False</span><span style="color:#E1E4E8">)</span></span>
<span class="line"></span></code></pre>
<p>代码解析：</p>
<h4 id="create_model">create_model</h4>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">def</span><span style="color:#79B8FF"> __init__</span><span style="color:#E1E4E8">(self,</span></span>
<span class="line"><span style="color:#E1E4E8">             source_vocab_size, </span><span style="color:#6A737D"># 英文單詞表的數量</span></span>
<span class="line"><span style="color:#E1E4E8">             target_vocab_size, </span><span style="color:#6A737D"># 法文單詞表的數量</span></span>
<span class="line"><span style="color:#E1E4E8">             buckets, </span><span style="color:#6A737D"># buckets 於下面詳述</span></span>
<span class="line"><span style="color:#E1E4E8">             size, </span><span style="color:#6A737D"># 模型每個 layer 的 neuron size</span></span>
<span class="line"><span style="color:#E1E4E8">             num_layers, </span></span>
<span class="line"><span style="color:#E1E4E8">             max_gradient_norm,  </span><span style="color:#6A737D"># 訓練 RNN 時 clip 梯度的值</span></span>
<span class="line"><span style="color:#E1E4E8">             batch_size, </span></span>
<span class="line"><span style="color:#E1E4E8">             learning_rate,</span></span>
<span class="line"><span style="color:#E1E4E8">             learning_rate_decay_factor,</span></span>
<span class="line"><span style="color:#E1E4E8">             use_lstm</span><span style="color:#F97583">=</span><span style="color:#79B8FF">False</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#E1E4E8">             num_samples</span><span style="color:#F97583">=</span><span style="color:#79B8FF">512</span><span style="color:#E1E4E8">, </span><span style="color:#6A737D"># sampled softmax size</span></span>
<span class="line"><span style="color:#E1E4E8">             forward_only</span><span style="color:#F97583">=</span><span style="color:#79B8FF">False</span><span style="color:#E1E4E8">, </span><span style="color:#6A737D"># train時為False, decode時為true</span></span>
<span class="line"><span style="color:#E1E4E8">             dtype</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">tf.float32):</span></span>
<span class="line"></span></code></pre>
<p>初始化一个seq2seqModel class</p>
<h4 id="bucket说明">bucket说明</h4>
<p>Bucket 是工程上使用的一種方式。理論上 RNN 可以輸出任意長度的句子，但這樣勢必會因為每句話的長度不同，而產生許多無用的 graph。使用 Bucket 可以減少產生大量，並可能會有不少重複的 graph。若有一長度為 ( 6, 16 ) 的 (英文, 法文) 句子，那麼則會被分配到 (20, 25) 這個 bucket。並且英文會被 padding 至長度 20，法文會被 padding 至長度 25</p>
<h4 id="读入资料">读入资料</h4>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">def</span><span style="color:#B392F0"> read_data</span><span style="color:#E1E4E8">(source_path, target_path, max_size</span><span style="color:#F97583">=</span><span style="color:#79B8FF">None</span><span style="color:#E1E4E8">):</span></span>
<span class="line"><span style="color:#E1E4E8">  data_set </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> [[] </span><span style="color:#F97583">for</span><span style="color:#E1E4E8"> _ </span><span style="color:#F97583">in</span><span style="color:#E1E4E8"> _buckets]</span></span>
<span class="line"><span style="color:#6A737D">  # 讀入英文檔案</span></span>
<span class="line"><span style="color:#F97583">  with</span><span style="color:#E1E4E8"> tf.gfile.GFile(source_path, </span><span style="color:#FFAB70">mode</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"r"</span><span style="color:#E1E4E8">) </span><span style="color:#F97583">as</span><span style="color:#E1E4E8"> source_file:</span></span>
<span class="line"><span style="color:#6A737D">    # 讀入法文檔案</span></span>
<span class="line"><span style="color:#F97583">    with</span><span style="color:#E1E4E8"> tf.gfile.GFile(target_path, </span><span style="color:#FFAB70">mode</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"r"</span><span style="color:#E1E4E8">) </span><span style="color:#F97583">as</span><span style="color:#E1E4E8"> target_file:</span></span>
<span class="line"><span style="color:#6A737D">      # 每次讀入一行例如 ( '1 2 3 4 5\n', '99 98 97 96 95\n') 的(英,法)句對</span></span>
<span class="line"><span style="color:#E1E4E8">      source, target </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> source_file.readline(), target_file.readline()</span></span>
<span class="line"><span style="color:#E1E4E8">      counter </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> 0</span></span>
<span class="line"><span style="color:#6A737D">      # 逐行處理，去除 \n，並且 tokenize 化</span></span>
<span class="line"><span style="color:#F97583">      while</span><span style="color:#E1E4E8"> source </span><span style="color:#F97583">and</span><span style="color:#E1E4E8"> target </span><span style="color:#F97583">and</span><span style="color:#E1E4E8"> (</span><span style="color:#F97583">not</span><span style="color:#E1E4E8"> max_size </span><span style="color:#F97583">or</span><span style="color:#E1E4E8"> counter </span><span style="color:#F97583">&#x3C;</span><span style="color:#E1E4E8"> max_size):</span></span>
<span class="line"><span style="color:#E1E4E8">        counter </span><span style="color:#F97583">+=</span><span style="color:#79B8FF"> 1</span></span>
<span class="line"><span style="color:#F97583">        if</span><span style="color:#E1E4E8"> counter </span><span style="color:#F97583">%</span><span style="color:#79B8FF"> 100000</span><span style="color:#F97583"> ==</span><span style="color:#79B8FF"> 0</span><span style="color:#E1E4E8">:</span></span>
<span class="line"><span style="color:#79B8FF">          print</span><span style="color:#E1E4E8">(</span><span style="color:#9ECBFF">"  reading data line </span><span style="color:#79B8FF">%d</span><span style="color:#9ECBFF">"</span><span style="color:#F97583"> %</span><span style="color:#E1E4E8"> counter)</span></span>
<span class="line"><span style="color:#E1E4E8">          sys.stdout.flush()</span></span>
<span class="line"><span style="color:#E1E4E8">        source_ids </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> [</span><span style="color:#79B8FF">int</span><span style="color:#E1E4E8">(x) </span><span style="color:#F97583">for</span><span style="color:#E1E4E8"> x </span><span style="color:#F97583">in</span><span style="color:#E1E4E8"> source.split()]</span></span>
<span class="line"><span style="color:#E1E4E8">        target_ids </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> [</span><span style="color:#79B8FF">int</span><span style="color:#E1E4E8">(x) </span><span style="color:#F97583">for</span><span style="color:#E1E4E8"> x </span><span style="color:#F97583">in</span><span style="color:#E1E4E8"> target.split()]</span></span>
<span class="line"><span style="color:#E1E4E8">        target_ids.append(data_utils.</span><span style="color:#79B8FF">EOS_ID</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#6A737D">        # 這邊計算每句話的長度，並且分配到適合該長度的 bucket 之中</span></span>
<span class="line"><span style="color:#F97583">        for</span><span style="color:#E1E4E8"> bucket_id, (source_size, target_size) </span><span style="color:#F97583">in</span><span style="color:#79B8FF"> enumerate</span><span style="color:#E1E4E8">(_buckets):</span></span>
<span class="line"><span style="color:#F97583">          if</span><span style="color:#79B8FF"> len</span><span style="color:#E1E4E8">(source_ids) </span><span style="color:#F97583">&#x3C;</span><span style="color:#E1E4E8"> source_size </span><span style="color:#F97583">and</span><span style="color:#79B8FF"> len</span><span style="color:#E1E4E8">(target_ids) </span><span style="color:#F97583">&#x3C;</span><span style="color:#E1E4E8"> target_size:</span></span>
<span class="line"><span style="color:#E1E4E8">            data_set[bucket_id].append([source_ids, target_ids])</span></span>
<span class="line"><span style="color:#F97583">            break</span></span>
<span class="line"><span style="color:#E1E4E8">        source, target </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> source_file.readline(), target_file.readline()</span></span>
<span class="line"><span style="color:#F97583">  return</span><span style="color:#E1E4E8"> data_set</span></span>
<span class="line"></span></code></pre>
<h4 id="建立batch">建立batch</h4>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#E1E4E8">random_number_01 </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> np.random.random_sample()</span></span>
<span class="line"><span style="color:#E1E4E8">bucket_id </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> min</span><span style="color:#E1E4E8">([i </span><span style="color:#F97583">for</span><span style="color:#E1E4E8"> i </span><span style="color:#F97583">in</span><span style="color:#FFAB70"> xrange</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">len</span><span style="color:#E1E4E8">(train_buckets_scale))</span></span>
<span class="line"><span style="color:#F97583">                       if</span><span style="color:#E1E4E8"> train_buckets_scale[i] </span><span style="color:#F97583">></span><span style="color:#E1E4E8"> random_number_01])</span></span>
<span class="line"><span style="color:#E1E4E8">encoder_inputs, decoder_inputs, target_weights </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> model.get_batch(</span></span>
<span class="line"><span style="color:#E1E4E8">          train_set, bucket_id)</span></span>
<span class="line"></span></code></pre>
<p>还需要class本身的property:<code>batch_size</code></p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">def</span><span style="color:#B392F0"> get_batch</span><span style="color:#E1E4E8">(self, data, bucket_id):</span></span>
<span class="line"><span style="color:#6A737D">  # 根據傳進來的 bucket_id 決定這次的 encoder, deocder size，例如 5, 10</span></span>
<span class="line"><span style="color:#E1E4E8">  encoder_size, decoder_size </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> self</span><span style="color:#E1E4E8">.buckets[bucket_id]</span></span>
<span class="line"><span style="color:#E1E4E8">  encoder_inputs, decoder_inputs </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> [], []</span></span>
<span class="line"><span style="color:#6A737D">  # Get a random batch of encoder and decoder inputs from data,</span></span>
<span class="line"><span style="color:#6A737D">  # pad them if needed, reverse encoder inputs and add GO to decoder.</span></span>
<span class="line"><span style="color:#F97583">  for</span><span style="color:#E1E4E8"> _ </span><span style="color:#F97583">in</span><span style="color:#FFAB70"> xrange</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">self</span><span style="color:#E1E4E8">.batch_size):</span></span>
<span class="line"><span style="color:#6A737D">    # 前面提過 data 是一個長度為4的list，data[i] 存放長度符合 bucket[i] 的資料</span></span>
<span class="line"><span style="color:#E1E4E8">    encoder_input, decoder_input </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> random.choice(data[bucket_id])</span></span>
<span class="line"><span style="color:#6A737D">    # Encoder inputs are padded and then reversed.</span></span>
<span class="line"><span style="color:#E1E4E8">    encoder_pad </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> [data_utils.</span><span style="color:#79B8FF">PAD_ID</span><span style="color:#E1E4E8">] </span><span style="color:#F97583">*</span><span style="color:#E1E4E8"> (encoder_size </span><span style="color:#F97583">-</span><span style="color:#79B8FF"> len</span><span style="color:#E1E4E8">(encoder_input))</span></span>
<span class="line"><span style="color:#E1E4E8">    encoder_inputs.append(</span><span style="color:#79B8FF">list</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">reversed</span><span style="color:#E1E4E8">(encoder_input </span><span style="color:#F97583">+</span><span style="color:#E1E4E8"> encoder_pad)))</span></span>
<span class="line"><span style="color:#6A737D">    # Decoder inputs get an extra "GO" symbol, and are padded then.</span></span>
<span class="line"><span style="color:#E1E4E8">    decoder_pad_size </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> decoder_size </span><span style="color:#F97583">-</span><span style="color:#79B8FF"> len</span><span style="color:#E1E4E8">(decoder_input) </span><span style="color:#F97583">-</span><span style="color:#79B8FF"> 1</span></span>
<span class="line"><span style="color:#E1E4E8">    decoder_inputs.append([data_utils.</span><span style="color:#79B8FF">GO_ID</span><span style="color:#E1E4E8">] </span><span style="color:#F97583">+</span><span style="color:#E1E4E8"> decoder_input </span><span style="color:#F97583">+</span></span>
<span class="line"><span style="color:#E1E4E8">                          [data_utils.</span><span style="color:#79B8FF">PAD_ID</span><span style="color:#E1E4E8">] </span><span style="color:#F97583">*</span><span style="color:#E1E4E8"> decoder_pad_size)</span></span>
<span class="line"><span style="color:#6A737D">  # Now we create batch-major vectors from the data selected above.</span></span>
<span class="line"><span style="color:#E1E4E8">  batch_encoder_inputs, batch_decoder_inputs, batch_weights </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> [], [], []</span></span>
<span class="line"><span style="color:#6A737D">  # Batch encoder inputs are just re-indexed encoder_inputs.</span></span>
<span class="line"><span style="color:#F97583">  for</span><span style="color:#E1E4E8"> length_idx </span><span style="color:#F97583">in</span><span style="color:#FFAB70"> xrange</span><span style="color:#E1E4E8">(encoder_size):</span></span>
<span class="line"><span style="color:#E1E4E8">    batch_encoder_inputs.append(</span></span>
<span class="line"><span style="color:#E1E4E8">        np.array([encoder_inputs[batch_idx][length_idx]</span></span>
<span class="line"><span style="color:#F97583">                  for</span><span style="color:#E1E4E8"> batch_idx </span><span style="color:#F97583">in</span><span style="color:#FFAB70"> xrange</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">self</span><span style="color:#E1E4E8">.batch_size)], </span><span style="color:#FFAB70">dtype</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">np.int32))</span></span>
<span class="line"><span style="color:#6A737D">  # Batch decoder inputs are re-indexed decoder_inputs, we create weights.</span></span>
<span class="line"><span style="color:#F97583">  for</span><span style="color:#E1E4E8"> length_idx </span><span style="color:#F97583">in</span><span style="color:#FFAB70"> xrange</span><span style="color:#E1E4E8">(decoder_size):</span></span>
<span class="line"><span style="color:#E1E4E8">    batch_decoder_inputs.append(</span></span>
<span class="line"><span style="color:#E1E4E8">        np.array([decoder_inputs[batch_idx][length_idx]</span></span>
<span class="line"><span style="color:#F97583">                  for</span><span style="color:#E1E4E8"> batch_idx </span><span style="color:#F97583">in</span><span style="color:#FFAB70"> xrange</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">self</span><span style="color:#E1E4E8">.batch_size)], </span><span style="color:#FFAB70">dtype</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">np.int32))</span></span>
<span class="line"><span style="color:#6A737D">    # Create target_weights to be 0 for targets that are padding.</span></span>
<span class="line"><span style="color:#6A737D">    # 這個 weights 是給模型訓練用的，有目標值的地方為1，其他為0</span></span>
<span class="line"><span style="color:#6A737D">    # 有目標值的地方，指的是 decoder_input 平移1格的結果</span></span>
<span class="line"><span style="color:#E1E4E8">    batch_weight </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> np.ones(</span><span style="color:#79B8FF">self</span><span style="color:#E1E4E8">.batch_size, </span><span style="color:#FFAB70">dtype</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">np.float32)</span></span>
<span class="line"><span style="color:#F97583">    for</span><span style="color:#E1E4E8"> batch_idx </span><span style="color:#F97583">in</span><span style="color:#FFAB70"> xrange</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">self</span><span style="color:#E1E4E8">.batch_size):</span></span>
<span class="line"><span style="color:#6A737D">      # We set weight to 0 if the corresponding target is a PAD symbol.</span></span>
<span class="line"><span style="color:#6A737D">      # The corresponding target is decoder_input shifted by 1 forward.</span></span>
<span class="line"><span style="color:#F97583">       if</span><span style="color:#E1E4E8"> length_idx </span><span style="color:#F97583">&#x3C;</span><span style="color:#E1E4E8"> decoder_size </span><span style="color:#F97583">-</span><span style="color:#79B8FF"> 1</span><span style="color:#E1E4E8">:</span></span>
<span class="line"><span style="color:#E1E4E8">           target </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> decoder_inputs[batch_idx][length_idx </span><span style="color:#F97583">+</span><span style="color:#79B8FF"> 1</span><span style="color:#E1E4E8">]</span></span>
<span class="line"><span style="color:#F97583">       if</span><span style="color:#E1E4E8"> length_idx </span><span style="color:#F97583">==</span><span style="color:#E1E4E8"> decoder_size </span><span style="color:#F97583">-</span><span style="color:#79B8FF"> 1</span><span style="color:#F97583"> or</span><span style="color:#E1E4E8"> target </span><span style="color:#F97583">==</span><span style="color:#E1E4E8"> data_utils.</span><span style="color:#79B8FF">PAD_ID</span><span style="color:#E1E4E8">:</span></span>
<span class="line"><span style="color:#E1E4E8">           batch_weight[batch_idx] </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> 0.0</span></span>
<span class="line"><span style="color:#E1E4E8">    batch_weights.append(batch_weight)</span></span>
<span class="line"><span style="color:#F97583">  return</span><span style="color:#E1E4E8"> batch_encoder_inputs, batch_decoder_inputs, batch_weights</span></span>
<span class="line"></span></code></pre>
<h4 id="训练">训练</h4>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#79B8FF">self</span><span style="color:#E1E4E8">.outputs, </span><span style="color:#79B8FF">self</span><span style="color:#E1E4E8">.losses </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> tf.contrib.legacy_seq2seq.model_with_buckets(</span></span>
<span class="line"><span style="color:#79B8FF">    self</span><span style="color:#E1E4E8">.encoder_inputs, </span><span style="color:#79B8FF">self</span><span style="color:#E1E4E8">.decoder_inputs, targets,</span></span>
<span class="line"><span style="color:#79B8FF">    self</span><span style="color:#E1E4E8">.target_weights, buckets,</span></span>
<span class="line"><span style="color:#FFAB70">    seq2seq</span><span style="color:#F97583">=lambda</span><span style="color:#E1E4E8"> x, y: seq2seq_f(x, y, </span><span style="color:#79B8FF">False</span><span style="color:#E1E4E8">),</span></span>
<span class="line"><span style="color:#FFAB70">    softmax_loss_function</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">softmax_loss_function)</span></span>
<span class="line"></span></code></pre>
<p>上面這段程式碼中的 seq2seq 參數 <code>seq2seq_f(x, y, False)</code> 也是定義在 <code>seq2seq_model.py</code> 裡面的。指的是將 x: encoder_input 與 y: decoder_input 輸入，回傳的就是這個 seq2seq model 的 output 與 state。False 這個參數則是 <code>seq2seq_f()</code> 裡面自行定義作為 do_decode or not 的 Boolean。我們把相關的程式碼列出來如下，可以看到多為 tensorflow 之中對於 RNN 的設定。其中比較特別的是 <code>sampled_softmax_loss</code> 以及 <code>seq2seq_f</code></p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#E1E4E8">output_projection </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> None</span></span>
<span class="line"><span style="color:#E1E4E8">softmax_loss_function </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> None</span></span>
<span class="line"><span style="color:#6A737D"># Sampled softmax only makes sense if we sample less than vocabulary size.</span></span>
<span class="line"><span style="color:#F97583">if</span><span style="color:#E1E4E8"> num_samples </span><span style="color:#F97583">></span><span style="color:#79B8FF"> 0</span><span style="color:#F97583"> and</span><span style="color:#E1E4E8"> num_samples </span><span style="color:#F97583">&#x3C;</span><span style="color:#79B8FF"> self</span><span style="color:#E1E4E8">.target_vocab_size:</span></span>
<span class="line"><span style="color:#E1E4E8">  w_t </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> tf.get_variable(</span><span style="color:#9ECBFF">"proj_w"</span><span style="color:#E1E4E8">, [</span><span style="color:#79B8FF">self</span><span style="color:#E1E4E8">.target_vocab_size, size], </span><span style="color:#FFAB70">dtype</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">dtype)</span></span>
<span class="line"><span style="color:#E1E4E8">  w </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> tf.transpose(w_t)</span></span>
<span class="line"><span style="color:#E1E4E8">  b </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> tf.get_variable(</span><span style="color:#9ECBFF">"proj_b"</span><span style="color:#E1E4E8">, [</span><span style="color:#79B8FF">self</span><span style="color:#E1E4E8">.target_vocab_size], </span><span style="color:#FFAB70">dtype</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">dtype)</span></span>
<span class="line"><span style="color:#E1E4E8">  output_projection </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> (w, b)</span></span>
<span class="line"><span style="color:#F97583">  def</span><span style="color:#B392F0"> sampled_loss</span><span style="color:#E1E4E8">(labels, inputs):</span></span>
<span class="line"><span style="color:#E1E4E8">    labels </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> tf.reshape(labels, [</span><span style="color:#F97583">-</span><span style="color:#79B8FF">1</span><span style="color:#E1E4E8">, </span><span style="color:#79B8FF">1</span><span style="color:#E1E4E8">])</span></span>
<span class="line"><span style="color:#6A737D">    # We need to compute the sampled_softmax_loss using 32bit floats to</span></span>
<span class="line"><span style="color:#6A737D">    # avoid numerical instabilities.</span></span>
<span class="line"><span style="color:#E1E4E8">    local_w_t </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> tf.cast(w_t, tf.float32)</span></span>
<span class="line"><span style="color:#E1E4E8">    local_b </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> tf.cast(b, tf.float32)</span></span>
<span class="line"><span style="color:#E1E4E8">    local_inputs </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> tf.cast(inputs, tf.float32)</span></span>
<span class="line"><span style="color:#F97583">    return</span><span style="color:#E1E4E8"> tf.cast(</span></span>
<span class="line"><span style="color:#E1E4E8">        tf.nn.sampled_softmax_loss(</span></span>
<span class="line"><span style="color:#FFAB70">            weights</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">local_w_t,</span></span>
<span class="line"><span style="color:#FFAB70">            biases</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">local_b,</span></span>
<span class="line"><span style="color:#FFAB70">            labels</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">labels,</span></span>
<span class="line"><span style="color:#FFAB70">            inputs</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">local_inputs,</span></span>
<span class="line"><span style="color:#FFAB70">            num_sampled</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">num_samples,</span></span>
<span class="line"><span style="color:#FFAB70">            num_classes</span><span style="color:#F97583">=</span><span style="color:#79B8FF">self</span><span style="color:#E1E4E8">.target_vocab_size),</span></span>
<span class="line"><span style="color:#E1E4E8">        dtype)</span></span>
<span class="line"><span style="color:#E1E4E8">  softmax_loss_function </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> sampled_loss</span></span>
<span class="line"><span style="color:#E1E4E8">    </span></span>
<span class="line"><span style="color:#6A737D"># Create the internal multi-layer cell for our RNN.</span></span>
<span class="line"><span style="color:#F97583">def</span><span style="color:#B392F0"> single_cell</span><span style="color:#E1E4E8">():</span></span>
<span class="line"><span style="color:#F97583">  return</span><span style="color:#E1E4E8"> tf.contrib.rnn.GRUCell(size)</span></span>
<span class="line"><span style="color:#F97583">if</span><span style="color:#E1E4E8"> use_lstm:</span></span>
<span class="line"><span style="color:#F97583">  def</span><span style="color:#B392F0"> single_cell</span><span style="color:#E1E4E8">():</span></span>
<span class="line"><span style="color:#F97583">    return</span><span style="color:#E1E4E8"> tf.contrib.rnn.BasicLSTMCell(size)</span></span>
<span class="line"><span style="color:#E1E4E8">cell </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> single_cell()</span></span>
<span class="line"><span style="color:#F97583">if</span><span style="color:#E1E4E8"> num_layers </span><span style="color:#F97583">></span><span style="color:#79B8FF"> 1</span><span style="color:#E1E4E8">:</span></span>
<span class="line"><span style="color:#E1E4E8">  cell </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> tf.contrib.rnn.MultiRNNCell([single_cell() </span><span style="color:#F97583">for</span><span style="color:#E1E4E8"> _ </span><span style="color:#F97583">in</span><span style="color:#79B8FF"> range</span><span style="color:#E1E4E8">(num_layers)])</span></span>
<span class="line"><span style="color:#6A737D"># The seq2seq function: we use embedding for the input and attention.</span></span>
<span class="line"><span style="color:#F97583">def</span><span style="color:#B392F0"> seq2seq_f</span><span style="color:#E1E4E8">(encoder_inputs, decoder_inputs, do_decode):</span></span>
<span class="line"><span style="color:#F97583">  return</span><span style="color:#E1E4E8"> tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(</span></span>
<span class="line"><span style="color:#E1E4E8">      encoder_inputs,</span></span>
<span class="line"><span style="color:#E1E4E8">      decoder_inputs,</span></span>
<span class="line"><span style="color:#E1E4E8">      cell,</span></span>
<span class="line"><span style="color:#FFAB70">      num_encoder_symbols</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">source_vocab_size,</span></span>
<span class="line"><span style="color:#FFAB70">      num_decoder_symbols</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">target_vocab_size,</span></span>
<span class="line"><span style="color:#FFAB70">      embedding_size</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">size,</span></span>
<span class="line"><span style="color:#FFAB70">      output_projection</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">output_projection,</span></span>
<span class="line"><span style="color:#FFAB70">      feed_previous</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">do_decode,</span></span>
<span class="line"><span style="color:#FFAB70">      dtype</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">dtype)  </span></span>
<span class="line"></span>
<span class="line"></span></code></pre>
<p><code>sampled_softmax_loss</code> 是用在當有大量的輸出類別必須被 predict 的時候，舉例來說，像是英翻法這樣的翻譯工作，法文的詞典(target_vocab_size) size 有 40000 之多，這時候我們採用 sampled_softmax_loss 可以快速有效地建立一個 softmax classifier。其中的參數<code>num_sampled</code>指的是 sampling 的數目，在這邊是512。<code>num_classes</code>指的就是實際的 class 數目，在這邊就是以法文詞典的數目來代表。要注意的是 <code>num_sampled</code>不可以大於 <code>num_classes</code> 就是了</p>
<p><code>seq2seq_f()</code> 直接呼叫了 <code>tf.contrib.legacy_seq2seq.embedding_attention_seq2seq()</code>。這個 embedding_attention_seq2seq 是一個帶有 embedding + sequence to sequence 並帶有 attention 機制的模型。encoder_input 首先進入一個 embedding layer，轉為 word vector，之後進入一個 encoder RNN。這個 encoder RNN 的每一個 time step 會被記錄下來，作為 attention 機制的參考。接下來，decoder_input 會進入另一個新建立的 embedding layer，在同樣轉為 word vector 之後，進入一個 attention deocder RNN。這個 deocder 是由 encoder 的最後一個 time step 的 state 進行初始化，其後每一個輸入就是 decoder_input 經過 embedding 之後的 word vector，並且具有對 encoder output 專注的 attention 機制</p>
<p>在 <code>tf.contrib.legacy_seq2seq.embedding_attention_seq2seq()</code> 之中的參數 <code>feed_previous</code>，當他為 False 的時候 decoder 會使用前面給的 decoer_input 作為輸入，也就是一般在訓練階段的作法。當值為 True 的時候，前面給的 decoder_input 只有第一個值（通常是 GO symbol，代表一個句子的開始） 會作為 decoder 的輸入，而 decoder 的下一個 input，則是 decoder 的前一個 output，也就是只給 deocder 第一個 input，後面讓他自由發揮的意思。這也是一般在 decode/predict 時候的作法。</p>
<h4 id="perplexity">perplexity</h4>
<p>$$
perplexity=e^{-l}, l=\frac{1}{M}\sum_{i=1}^{m}\log\left(p(s_i) \right )
$$</p>
<p>如同precision recall等指标一样，用来评估一个模型的好坏</p> </article>  </div>  </main> <footer class="animate" data-astro-cid-sz7xmlte> <div class="mx-auto max-w-screen-sm px-5">  <div class="flex justify-between items-center" data-astro-cid-sz7xmlte> <div data-astro-cid-sz7xmlte>
&copy; 2026 | Blog
</div> <div class="flex flex-wrap gap-1 items-center" data-astro-cid-sz7xmlte> <button id="light-theme-button" aria-label="Light theme" class="group size-8 flex items-center justify-center rounded-full" data-astro-cid-sz7xmlte> <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="group-hover:stroke-black group-hover:dark:stroke-white transition-colors duration-300 ease-in-out" data-astro-cid-sz7xmlte> <circle cx="12" cy="12" r="5" data-astro-cid-sz7xmlte></circle> <line x1="12" y1="1" x2="12" y2="3" data-astro-cid-sz7xmlte></line> <line x1="12" y1="21" x2="12" y2="23" data-astro-cid-sz7xmlte></line> <line x1="4.22" y1="4.22" x2="5.64" y2="5.64" data-astro-cid-sz7xmlte></line> <line x1="18.36" y1="18.36" x2="19.78" y2="19.78" data-astro-cid-sz7xmlte></line> <line x1="1" y1="12" x2="3" y2="12" data-astro-cid-sz7xmlte></line> <line x1="21" y1="12" x2="23" y2="12" data-astro-cid-sz7xmlte></line> <line x1="4.22" y1="19.78" x2="5.64" y2="18.36" data-astro-cid-sz7xmlte></line> <line x1="18.36" y1="5.64" x2="19.78" y2="4.22" data-astro-cid-sz7xmlte></line> </svg> </button> <button id="dark-theme-button" aria-label="Dark theme" class="group size-8 flex items-center justify-center rounded-full" data-astro-cid-sz7xmlte> <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="group-hover:stroke-black group-hover:dark:stroke-white transition-colors duration-300 ease-in-out" data-astro-cid-sz7xmlte> <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z" data-astro-cid-sz7xmlte></path> </svg> </button> <button id="system-theme-button" aria-label="System theme" class="group size-8 flex items-center justify-center rounded-full" data-astro-cid-sz7xmlte> <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="group-hover:stroke-black group-hover:dark:stroke-white transition-colors duration-300 ease-in-out" data-astro-cid-sz7xmlte> <rect x="2" y="3" width="20" height="14" rx="2" ry="2" data-astro-cid-sz7xmlte></rect> <line x1="8" y1="21" x2="16" y2="21" data-astro-cid-sz7xmlte></line> <line x1="12" y1="17" x2="12" y2="21" data-astro-cid-sz7xmlte></line> </svg> </button> </div> </div>  </div> </footer>  <script>
  function setTheme(theme) {
    document.documentElement.classList.remove("light", "dark", "system");
    
    if (theme === "system") {
      document.documentElement.classList.add("system");
      const systemTheme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "dark" : "light";
      document.documentElement.classList.add(systemTheme);
    } else {
      document.documentElement.classList.add(theme);
    }
    
    localStorage.setItem("theme", theme);
  }

  document.getElementById("light-theme-button")?.addEventListener("click", () => setTheme("light"));
  document.getElementById("dark-theme-button")?.addEventListener("click", () => setTheme("dark"));
  document.getElementById("system-theme-button")?.addEventListener("click", () => setTheme("system"));

  const savedTheme = localStorage.getItem("theme") || "system";
  setTheme(savedTheme);
</script>  </body> </html>